{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 4: Sentiment Modeling and Validation\n",
        "\n",
        "## Purpose\n",
        "Implement three sentiment analysis models (TextBlob, VADER, Transformer) using optimal preprocessing for each.\n",
        "\n",
        "## Objectives\n",
        "1. Apply TextBlob sentiment analysis to preprocessed text\n",
        "2. Apply VADER sentiment analysis to minimal-preprocessed text\n",
        "3. Apply Transformer model sentiment analysis\n",
        "4. Save sentiment results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessed data\n",
        "print(\"=\" * 60)\n",
        "print(\"LOADING PREPROCESSED DATA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df = pd.read_csv('../data/processed/02_preprocessed_data.csv')\n",
        "print(f\"Loaded dataset: {len(df):,} comments, {len(df.columns)} columns\")\n",
        "\n",
        "# Verify preprocessing columns exist\n",
        "required_cols = ['text_textblob', 'text_vader', 'text_transformer']\n",
        "for col in required_cols:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Required column {col} not found in dataset\")\n",
        "    print(f\"✓ {col} column found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: TextBlob Sentiment Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def get_textblob_sentiment(text):\n",
        "    \"\"\"\n",
        "    Apply TextBlob sentiment analysis.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    text : str\n",
        "        Preprocessed text for TextBlob\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple : (sentiment_label, polarity_score)\n",
        "    \"\"\"\n",
        "    if not text or pd.isna(text) or str(text).strip() == '':\n",
        "        return 'neutral', 0.0\n",
        "    \n",
        "    try:\n",
        "        blob = TextBlob(str(text))\n",
        "        polarity = blob.sentiment.polarity\n",
        "        \n",
        "        if polarity > 0.1:\n",
        "            label = 'positive'\n",
        "        elif polarity < -0.1:\n",
        "            label = 'negative'\n",
        "        else:\n",
        "            label = 'neutral'\n",
        "        \n",
        "        return label, polarity\n",
        "    except Exception as e:\n",
        "        return 'neutral', 0.0\n",
        "\n",
        "# Apply to text_textblob (heavy preprocessing)\n",
        "print(\"=\" * 60)\n",
        "print(\"APPLYING TEXTBLOB SENTIMENT ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "tqdm.pandas(desc=\"TextBlob\")\n",
        "df[['sentiment_textblob', 'polarity_textblob']] = df['text_textblob'].progress_apply(\n",
        "    lambda x: pd.Series(get_textblob_sentiment(x))\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ TextBlob complete\")\n",
        "print(f\"\\nDistribution:\")\n",
        "print(df['sentiment_textblob'].value_counts())\n",
        "print(f\"\\nPolarity statistics:\")\n",
        "print(f\"  Mean: {df['polarity_textblob'].mean():.3f}\")\n",
        "print(f\"  Median: {df['polarity_textblob'].median():.3f}\")\n",
        "print(f\"  Std: {df['polarity_textblob'].std():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def get_vader_sentiment(text):\n",
        "    \"\"\"\n",
        "    Apply VADER sentiment analysis.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    text : str\n",
        "        Minimal-preprocessed text (preserves punctuation, caps, emojis)\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple : (sentiment_label, compound_score)\n",
        "    \"\"\"\n",
        "    if not text or pd.isna(text) or str(text).strip() == '':\n",
        "        return 'neutral', 0.0\n",
        "    \n",
        "    try:\n",
        "        analyzer = SentimentIntensityAnalyzer()\n",
        "        scores = analyzer.polarity_scores(str(text))\n",
        "        compound = scores['compound']\n",
        "        \n",
        "        if compound >= 0.05:\n",
        "            label = 'positive'\n",
        "        elif compound <= -0.05:\n",
        "            label = 'negative'\n",
        "        else:\n",
        "            label = 'neutral'\n",
        "        \n",
        "        return label, compound\n",
        "    except Exception as e:\n",
        "        return 'neutral', 0.0\n",
        "\n",
        "# Apply to text_vader (minimal preprocessing - HAS punctuation, caps, emojis!)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"APPLYING VADER SENTIMENT ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "tqdm.pandas(desc=\"VADER\")\n",
        "df[['sentiment_vader', 'compound_vader']] = df['text_vader'].progress_apply(\n",
        "    lambda x: pd.Series(get_vader_sentiment(x))\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ VADER complete\")\n",
        "print(f\"\\nDistribution:\")\n",
        "print(df['sentiment_vader'].value_counts())\n",
        "print(f\"\\nCompound score statistics:\")\n",
        "print(f\"  Mean: {df['compound_vader'].mean():.3f}\")\n",
        "print(f\"  Median: {df['compound_vader'].median():.3f}\")\n",
        "print(f\"  Std: {df['compound_vader'].std():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "def get_optimal_batch_size(device):\n",
        "    \"\"\"Determine optimal batch size based on GPU memory.\"\"\"\n",
        "    if device == -1:  # CPU\n",
        "        return 8\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        if gpu_memory_gb >= 8:\n",
        "            return 64\n",
        "        elif gpu_memory_gb >= 4:\n",
        "            return 32\n",
        "        else:\n",
        "            return 16\n",
        "    return 8\n",
        "\n",
        "def get_transformer_sentiment_batch(texts, batch_size=32):\n",
        "    \"\"\"\n",
        "    Process sentiment analysis in batches for memory efficiency.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    texts : pd.Series or list\n",
        "        Texts to analyze\n",
        "    batch_size : int\n",
        "        Batch size for processing\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    list : List of sentiment results\n",
        "    \"\"\"\n",
        "    # Check device\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    print(f\"Using device: {'GPU' if device == 0 else 'CPU'}\")\n",
        "    \n",
        "    # Load model\n",
        "    print(\"Loading transformer model...\")\n",
        "    sentiment_pipeline = pipeline(\n",
        "        \"sentiment-analysis\",\n",
        "        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "        device=device,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "    \n",
        "    results = []\n",
        "    text_list = texts.tolist() if hasattr(texts, 'tolist') else list(texts)\n",
        "    \n",
        "    # Process in batches\n",
        "    for i in tqdm(range(0, len(text_list), batch_size), desc=\"Transformer inference\"):\n",
        "        batch = text_list[i:i+batch_size]\n",
        "        \n",
        "        # Handle empty strings\n",
        "        batch = [text if text and str(text).strip() else 'neutral text' for text in batch]\n",
        "        \n",
        "        try:\n",
        "            batch_results = sentiment_pipeline(batch)\n",
        "            results.extend(batch_results)\n",
        "            \n",
        "            # GPU memory management\n",
        "            if device == 0 and i % (batch_size * 10) == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error at batch {i}: {e}\")\n",
        "            results.extend([{'label': 'NEUTRAL', 'score': 0.0}] * len(batch))\n",
        "    \n",
        "    # Final cleanup\n",
        "    if device == 0:\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Apply to text_transformer (light preprocessing)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"APPLYING TRANSFORMER SENTIMENT ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "batch_size = get_optimal_batch_size(device)\n",
        "print(f\"Optimal batch size: {batch_size}\")\n",
        "\n",
        "transformer_results = get_transformer_sentiment_batch(\n",
        "    df['text_transformer'],\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Extract labels and scores\n",
        "df['sentiment_transformer'] = [r['label'].upper().replace('POSITIVE', 'positive').replace('NEGATIVE', 'negative').replace('NEUTRAL', 'neutral') \n",
        "                               for r in transformer_results]\n",
        "df['confidence_transformer'] = [r['score'] for r in transformer_results]\n",
        "\n",
        "print(f\"\\n✓ Transformer complete\")\n",
        "print(f\"\\nDistribution:\")\n",
        "print(df['sentiment_transformer'].value_counts())\n",
        "print(f\"\\nConfidence statistics:\")\n",
        "print(f\"  Mean: {df['confidence_transformer'].mean():.3f}\")\n",
        "print(f\"  Median: {df['confidence_transformer'].median():.3f}\")\n",
        "print(f\"  Std: {df['confidence_transformer'].std():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save sentiment results\n",
        "output_path = '../data/processed/03_sentiment_results.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SAVING SENTIMENT RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"✓ Sentiment results saved: {output_path}\")\n",
        "print(f\"  Rows: {len(df):,}\")\n",
        "print(f\"  Columns: {len(df.columns)}\")\n",
        "\n",
        "# Display sentiment columns\n",
        "print(\"\\nSentiment columns:\")\n",
        "sentiment_cols = [col for col in df.columns if 'sentiment' in col.lower() or 'polarity' in col.lower() or 'compound' in col.lower() or 'confidence' in col.lower()]\n",
        "for col in sentiment_cols:\n",
        "    print(f\"  - {col}\")\n",
        "\n",
        "# Summary of all models\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SENTIMENT ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nTextBlob:\")\n",
        "print(df['sentiment_textblob'].value_counts())\n",
        "print(\"\\nVADER:\")\n",
        "print(df['sentiment_vader'].value_counts())\n",
        "print(\"\\nTransformer:\")\n",
        "print(df['sentiment_transformer'].value_counts())\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"NOTEBOOK 4 COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Next step: Run Notebook 5 (Downstream Analysis and Reporting)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
