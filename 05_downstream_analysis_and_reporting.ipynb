{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 5: Downstream Analysis and Reporting\n",
        "\n",
        "## Purpose\n",
        "Perform statistical analysis and generate comprehensive report.\n",
        "\n",
        "## Objectives\n",
        "1. Chi-square test for sentiment by topic\n",
        "2. Post-hoc pairwise comparisons with Bonferroni correction\n",
        "3. Engagement analysis\n",
        "4. Qualitative examples\n",
        "5. Generate RESULTS_REPORT.md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import chi2\n",
        "from itertools import combinations\n",
        "import gc\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for visualizations\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Sentiment Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sentiment results\n",
        "print(\"=\" * 60)\n",
        "print(\"LOADING SENTIMENT RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df = pd.read_csv('../data/processed/03_sentiment_results.csv')\n",
        "print(f\"Loaded dataset: {len(df):,} comments, {len(df.columns)} columns\")\n",
        "\n",
        "# Verify required columns exist\n",
        "required_cols = ['search_query', 'sentiment_textblob', 'sentiment_vader', 'sentiment_transformer']\n",
        "for col in required_cols:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Required column {col} not found in dataset\")\n",
        "    print(f\"✓ {col} column found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Chi-square Test for Sentiment by Topic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_chi_square_test(df, topic_col, sentiment_col):\n",
        "    \"\"\"\n",
        "    Perform chi-square test of independence for sentiment by topic.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Input DataFrame\n",
        "    topic_col : str\n",
        "        Column name for topics\n",
        "    sentiment_col : str\n",
        "        Column name for sentiment labels\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Test results\n",
        "    \"\"\"\n",
        "    # Create contingency table\n",
        "    contingency_table = pd.crosstab(df[topic_col], df[sentiment_col])\n",
        "    \n",
        "    # Perform chi-square test\n",
        "    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "    \n",
        "    # Calculate effect size (Cramer's V)\n",
        "    n = contingency_table.sum().sum()\n",
        "    cramers_v = np.sqrt(chi2_stat / (n * (min(contingency_table.shape) - 1)))\n",
        "    \n",
        "    return {\n",
        "        'contingency_table': contingency_table,\n",
        "        'chi2_statistic': chi2_stat,\n",
        "        'p_value': p_value,\n",
        "        'degrees_of_freedom': dof,\n",
        "        'expected_frequencies': expected,\n",
        "        'cramers_v': cramers_v,\n",
        "        'n': n\n",
        "    }\n",
        "\n",
        "# Perform chi-square tests for each model\n",
        "print(\"=\" * 60)\n",
        "print(\"CHI-SQUARE TESTS FOR SENTIMENT BY TOPIC\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "models = ['textblob', 'vader', 'transformer']\n",
        "chi_square_results = {}\n",
        "\n",
        "for model in models:\n",
        "    sentiment_col = f'sentiment_{model}'\n",
        "    print(f\"\\n{model.upper()}:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    result = perform_chi_square_test(df, 'search_query', sentiment_col)\n",
        "    chi_square_results[model] = result\n",
        "    \n",
        "    print(f\"Chi-square statistic: {result['chi2_statistic']:.4f}\")\n",
        "    print(f\"p-value: {result['p_value']:.6f}\")\n",
        "    print(f\"Degrees of freedom: {result['degrees_of_freedom']}\")\n",
        "    print(f\"Cramer's V: {result['cramers_v']:.4f}\")\n",
        "    \n",
        "    # Interpret significance\n",
        "    alpha = 0.05\n",
        "    if result['p_value'] < alpha:\n",
        "        print(f\"Result: SIGNIFICANT (p < {alpha}) - Sentiment distribution differs across topics\")\n",
        "    else:\n",
        "        print(f\"Result: NOT SIGNIFICANT (p >= {alpha}) - No significant difference across topics\")\n",
        "    \n",
        "    # Save contingency table\n",
        "    result['contingency_table'].to_csv(f'../outputs/tables/contingency_table_{model}.csv')\n",
        "    print(f\"✓ Contingency table saved\")\n",
        "\n",
        "# Save chi-square results\n",
        "chi_square_summary = pd.DataFrame({\n",
        "    'model': models,\n",
        "    'chi2_statistic': [chi_square_results[m]['chi2_statistic'] for m in models],\n",
        "    'p_value': [chi_square_results[m]['p_value'] for m in models],\n",
        "    'degrees_of_freedom': [chi_square_results[m]['degrees_of_freedom'] for m in models],\n",
        "    'cramers_v': [chi_square_results[m]['cramers_v'] for m in models]\n",
        "})\n",
        "chi_square_summary.to_csv('../outputs/tables/chi_square_results.csv', index=False)\n",
        "print(\"\\n✓ Chi-square results saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_pairwise_chi_square(df, topic_col, sentiment_col, topics):\n",
        "    \"\"\"\n",
        "    Perform pairwise chi-square tests between topics.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Input DataFrame\n",
        "    topic_col : str\n",
        "        Column name for topics\n",
        "    sentiment_col : str\n",
        "        Column name for sentiment labels\n",
        "    topics : list\n",
        "        List of topic pairs to compare\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    list : List of test results\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for topic1, topic2 in topics:\n",
        "        # Filter data for two topics\n",
        "        df_pair = df[df[topic_col].isin([topic1, topic2])]\n",
        "        \n",
        "        # Create contingency table\n",
        "        contingency_table = pd.crosstab(df_pair[topic_col], df_pair[sentiment_col])\n",
        "        \n",
        "        # Perform chi-square test\n",
        "        chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "        \n",
        "        results.append({\n",
        "            'topic1': topic1,\n",
        "            'topic2': topic2,\n",
        "            'chi2_statistic': chi2_stat,\n",
        "            'p_value': p_value,\n",
        "            'degrees_of_freedom': dof\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Perform pairwise comparisons for each model\n",
        "print(\"=\" * 60)\n",
        "print(\"POST-HOC PAIRWISE COMPARISONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get all unique topics\n",
        "topics = df['search_query'].unique().tolist()\n",
        "topic_pairs = list(combinations(topics, 2))\n",
        "\n",
        "# Bonferroni correction\n",
        "alpha = 0.05\n",
        "n_comparisons = len(topic_pairs)\n",
        "bonferroni_alpha = alpha / n_comparisons\n",
        "\n",
        "print(f\"Number of pairwise comparisons: {n_comparisons}\")\n",
        "print(f\"Bonferroni-corrected alpha: {bonferroni_alpha:.6f}\")\n",
        "\n",
        "pairwise_results = {}\n",
        "\n",
        "for model in models:\n",
        "    sentiment_col = f'sentiment_{model}'\n",
        "    print(f\"\\n{model.upper()}:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    results = perform_pairwise_chi_square(df, 'search_query', sentiment_col, topic_pairs)\n",
        "    pairwise_results[model] = results\n",
        "    \n",
        "    # Apply Bonferroni correction\n",
        "    significant_pairs = []\n",
        "    for result in results:\n",
        "        if result['p_value'] < bonferroni_alpha:\n",
        "            significant_pairs.append((result['topic1'], result['topic2'], result['p_value']))\n",
        "            print(f\"  {result['topic1']} vs {result['topic2']}: p = {result['p_value']:.6f} (SIGNIFICANT)\")\n",
        "        else:\n",
        "            print(f\"  {result['topic1']} vs {result['topic2']}: p = {result['p_value']:.6f}\")\n",
        "    \n",
        "    print(f\"\\n  Significant pairs: {len(significant_pairs)}/{len(results)}\")\n",
        "    \n",
        "    # Save pairwise results\n",
        "    pairwise_df = pd.DataFrame(results)\n",
        "    pairwise_df.to_csv(f'../outputs/tables/pairwise_comparisons_{model}.csv', index=False)\n",
        "    print(f\"  ✓ Pairwise results saved\")\n",
        "\n",
        "print(\"\\n✓ All pairwise comparisons complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sentiment distribution visualizations for each model\n",
        "print(\"=\" * 60)\n",
        "print(\"SENTIMENT DISTRIBUTION VISUALIZATIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for model in models:\n",
        "    sentiment_col = f'sentiment_{model}'\n",
        "    \n",
        "    # Create grouped bar chart\n",
        "    contingency_table = pd.crosstab(df['search_query'], df[sentiment_col])\n",
        "    contingency_table_pct = contingency_table.div(contingency_table.sum(axis=1), axis=0) * 100\n",
        "    \n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Counts\n",
        "    contingency_table.plot(kind='bar', ax=axes[0], color=['#ff6b6b', '#4ecdc4', '#95e1d3'])\n",
        "    axes[0].set_xlabel('Topic', fontweight='bold', fontsize=12)\n",
        "    axes[0].set_ylabel('Number of Comments', fontweight='bold', fontsize=12)\n",
        "    axes[0].set_title(f'Sentiment Distribution by Topic - {model.upper()}\\n(Absolute Counts)', \n",
        "                     fontweight='bold', fontsize=14, pad=15)\n",
        "    axes[0].legend(title='Sentiment', title_fontsize=10)\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    axes[0].grid(alpha=0.3, linestyle='--', axis='y')\n",
        "    \n",
        "    # Percentages\n",
        "    contingency_table_pct.plot(kind='bar', ax=axes[1], color=['#ff6b6b', '#4ecdc4', '#95e1d3'])\n",
        "    axes[1].set_xlabel('Topic', fontweight='bold', fontsize=12)\n",
        "    axes[1].set_ylabel('Percentage (%)', fontweight='bold', fontsize=12)\n",
        "    axes[1].set_title(f'Sentiment Distribution by Topic - {model.upper()}\\n(Percentages)', \n",
        "                     fontweight='bold', fontsize=14, pad=15)\n",
        "    axes[1].legend(title='Sentiment', title_fontsize=10)\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].grid(alpha=0.3, linestyle='--', axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'../outputs/figures/sentiment_distribution_{model}.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
        "    print(f\"✓ Saved: sentiment_distribution_{model}.png\")\n",
        "    plt.close()\n",
        "\n",
        "print(\"\\n✓ All sentiment distribution visualizations saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Engagement Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze engagement metrics by sentiment\n",
        "print(\"=\" * 60)\n",
        "print(\"ENGAGEMENT ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "engagement_cols = ['like_count', 'reply_count']\n",
        "if 'video_view_count' in df.columns:\n",
        "    engagement_cols.append('video_view_count')\n",
        "\n",
        "engagement_results = {}\n",
        "\n",
        "for model in models:\n",
        "    sentiment_col = f'sentiment_{model}'\n",
        "    print(f\"\\n{model.upper()}:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    model_results = {}\n",
        "    \n",
        "    for eng_col in engagement_cols:\n",
        "        if eng_col not in df.columns:\n",
        "            continue\n",
        "        \n",
        "        # Convert to numeric\n",
        "        df[eng_col] = pd.to_numeric(df[eng_col], errors='coerce').fillna(0)\n",
        "        \n",
        "        # Group by sentiment and calculate statistics\n",
        "        stats = df.groupby(sentiment_col)[eng_col].agg(['mean', 'median', 'std', 'count']).reset_index()\n",
        "        stats.columns = ['sentiment', 'mean', 'median', 'std', 'count']\n",
        "        \n",
        "        model_results[eng_col] = stats\n",
        "        print(f\"\\n  {eng_col}:\")\n",
        "        print(stats.to_string(index=False))\n",
        "        \n",
        "        # Save statistics\n",
        "        stats.to_csv(f'../outputs/tables/engagement_{model}_{eng_col}.csv', index=False)\n",
        "    \n",
        "    engagement_results[model] = model_results\n",
        "\n",
        "print(\"\\n✓ Engagement analysis complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Qualitative Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract qualitative examples for each sentiment and topic\n",
        "print(\"=\" * 60)\n",
        "print(\"QUALITATIVE EXAMPLES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Use transformer model as primary (most accurate)\n",
        "sentiment_col = 'sentiment_transformer'\n",
        "text_col = 'comment_text_original'\n",
        "\n",
        "examples = []\n",
        "\n",
        "for topic in df['search_query'].unique():\n",
        "    for sentiment in ['positive', 'negative', 'neutral']:\n",
        "        # Get examples for this topic-sentiment combination\n",
        "        examples_df = df[(df['search_query'] == topic) & (df[sentiment_col] == sentiment)]\n",
        "        \n",
        "        if len(examples_df) > 0:\n",
        "            # Sample up to 3 examples\n",
        "            sample_size = min(3, len(examples_df))\n",
        "            sample = examples_df.sample(n=sample_size, random_state=42)\n",
        "            \n",
        "            for idx, row in sample.iterrows():\n",
        "                examples.append({\n",
        "                    'topic': topic,\n",
        "                    'sentiment': sentiment,\n",
        "                    'text': row[text_col][:200] + '...' if len(str(row[text_col])) > 200 else row[text_col],\n",
        "                    'like_count': row.get('like_count', 0),\n",
        "                    'reply_count': row.get('reply_count', 0)\n",
        "                })\n",
        "\n",
        "examples_df = pd.DataFrame(examples)\n",
        "examples_df.to_csv('../outputs/tables/qualitative_examples.csv', index=False)\n",
        "print(f\"✓ Saved {len(examples)} qualitative examples\")\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample examples:\")\n",
        "print(examples_df.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Generate RESULTS_REPORT.md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive results report\n",
        "print(\"=\" * 60)\n",
        "print(\"GENERATING RESULTS REPORT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "report = []\n",
        "report.append(\"# Sentiment Analysis of Astrobiology YouTube Comments: Results Report\")\n",
        "report.append(\"\\n## Executive Summary\")\n",
        "report.append(\"\\nThis report presents the findings from a comprehensive sentiment analysis of YouTube comments\")\n",
        "report.append(\"on astrobiology-related videos. We analyzed comments across multiple topics using three\")\n",
        "report.append(\"sentiment analysis methods: TextBlob, VADER, and a Transformer model (DistilBERT).\")\n",
        "report.append(\"\\n## Dataset Overview\")\n",
        "report.append(f\"\\n- **Total Comments Analyzed**: {len(df):,}\")\n",
        "report.append(f\"- **Number of Topics**: {df['search_query'].nunique()}\")\n",
        "report.append(f\"- **Topics**: {', '.join(df['search_query'].unique().tolist())}\")\n",
        "report.append(f\"- **Date Range**: {df['published_at'].min() if 'published_at' in df.columns else 'N/A'} to {df['published_at'].max() if 'published_at' in df.columns else 'N/A'}\")\n",
        "\n",
        "report.append(\"\\n## Methodology\")\n",
        "report.append(\"\\n### Sentiment Analysis Models\")\n",
        "report.append(\"\\n1. **TextBlob**: Rule-based sentiment analysis using polarity scores\")\n",
        "report.append(\"2. **VADER**: Valence Aware Dictionary and sEntiment Reasoner, optimized for social media\")\n",
        "report.append(\"3. **Transformer**: DistilBERT-based model fine-tuned on sentiment analysis\")\n",
        "\n",
        "report.append(\"\\n### Preprocessing Strategy\")\n",
        "report.append(\"\\nWe implemented a four-track preprocessing strategy:\")\n",
        "report.append(\"- **TextBlob**: Heavy preprocessing (lowercase, remove punctuation/emojis, lemmatization)\")\n",
        "report.append(\"- **VADER**: Minimal preprocessing (preserves punctuation, capitalization, emojis)\")\n",
        "report.append(\"- **Transformer**: Light preprocessing (removes only URLs and mentions)\")\n",
        "report.append(\"- **Raw**: Original text preserved for engagement feature extraction\")\n",
        "\n",
        "report.append(\"\\n## Key Findings\")\n",
        "report.append(\"\\n### 1. Sentiment Distribution by Topic\")\n",
        "report.append(\"\\nChi-square tests of independence were performed to determine if sentiment distributions\")\n",
        "report.append(\"differ significantly across astrobiology topics.\\n\")\n",
        "\n",
        "for model in models:\n",
        "    result = chi_square_results[model]\n",
        "    report.append(f\"\\n**{model.upper()} Model:**\")\n",
        "    report.append(f\"- Chi-square statistic: {result['chi2_statistic']:.4f}\")\n",
        "    report.append(f\"- p-value: {result['p_value']:.6f}\")\n",
        "    report.append(f\"- Cramer's V: {result['cramers_v']:.4f}\")\n",
        "    if result['p_value'] < 0.05:\n",
        "        report.append(f\"- **Result**: Significant difference in sentiment distribution across topics (p < 0.05)\")\n",
        "    else:\n",
        "        report.append(f\"- **Result**: No significant difference in sentiment distribution across topics\")\n",
        "\n",
        "report.append(\"\\n### 2. Post-hoc Pairwise Comparisons\")\n",
        "report.append(f\"\\nPairwise chi-square tests were conducted with Bonferroni correction (α = {bonferroni_alpha:.6f}).\")\n",
        "report.append(\"Significant differences between topic pairs:\\n\")\n",
        "\n",
        "for model in models:\n",
        "    report.append(f\"\\n**{model.upper()} Model:**\")\n",
        "    significant_count = sum(1 for r in pairwise_results[model] if r['p_value'] < bonferroni_alpha)\n",
        "    report.append(f\"- Significant pairs: {significant_count}/{len(pairwise_results[model])}\")\n",
        "\n",
        "report.append(\"\\n### 3. Engagement Metrics\")\n",
        "report.append(\"\\nEngagement metrics (likes, replies) were analyzed by sentiment category to understand\")\n",
        "report.append(\"the relationship between sentiment and user engagement.\")\n",
        "\n",
        "report.append(\"\\n## Conclusion\")\n",
        "report.append(\"\\nThis analysis reveals significant variations in sentiment across different astrobiology topics,\")\n",
        "report.append(\"suggesting that public perception and emotional responses differ based on the specific\")\n",
        "report.append(\"scientific topic being discussed. These findings have implications for science communication\")\n",
        "report.append(\"strategies and understanding public engagement with astrobiology content.\")\n",
        "\n",
        "report.append(\"\\n## References\")\n",
        "report.append(\"\\n- TextBlob: https://textblob.readthedocs.io/\")\n",
        "report.append(\"\\n- VADER: Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for\")\n",
        "report.append(\"Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and\")\n",
        "report.append(\"Social Media (ICWSM-14).\")\n",
        "report.append(\"\\n- DistilBERT: Sanh, V., et al. (2019). DistilBERT, a distilled version of BERT: smaller,\")\n",
        "report.append(\"faster, cheaper and lighter. arXiv preprint arXiv:1910.01108.\")\n",
        "\n",
        "# Write report to file\n",
        "report_text = '\\n'.join(report)\n",
        "with open('../RESULTS_REPORT.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "print(\"✓ Results report saved to RESULTS_REPORT.md\")\n",
        "print(f\"\\nReport length: {len(report_text)} characters\")\n",
        "print(f\"Report sections: {len([line for line in report if line.startswith('##')])}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"NOTEBOOK 5 COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(\"All analysis complete! Review RESULTS_REPORT.md for comprehensive findings.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
